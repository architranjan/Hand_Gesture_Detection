# -*- coding: utf-8 -*-
"""hand-gesture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17yS8JG95WD4jLPIEOcGD63EZ_pG6jezQ
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d gti-upm/leapgestrecog

import zipfile
zip_ref = zipfile.ZipFile('/content/leapgestrecog.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import os
path = '/content/leapGestRecog'
total_images = 0
for dirname, _, filenames in os.walk(path):
    total_images += len(filenames)
print(f"Total images in leapGestRecog: {total_images}")

import os
import shutil


source_dir = '/content/leapGestRecog'


output_base_dir = '/content/processed_gestures'


os.makedirs(output_base_dir, exist_ok=True)


gesture_names = [
    '01_palm',
    '02_l',
    '03_fist',
    '04_fist_moved',
    '05_thumb',
    '06_index',
    '07_ok',
    '08_palm_moved',
    '09_c',
    '10_down'
]


for gesture_name in gesture_names:
    os.makedirs(os.path.join(output_base_dir, gesture_name), exist_ok=True)


for root, dirs, files in os.walk(source_dir):
    for dir_name in dirs:

        if dir_name in gesture_names:
            source_sub_dir = os.path.join(root, dir_name)
            destination_sub_dir = os.path.join(output_base_dir, dir_name)


            for sub_root, sub_dirs, sub_files in os.walk(source_sub_dir):
                for file in sub_files:

                    source_file_path = os.path.join(sub_root, file)


                    destination_file_path = os.path.join(destination_sub_dir, file)


                    shutil.copy2(source_file_path, destination_file_path)

print("Finished organizing the dataset.")

image_count = 0
for root, dirs, files in os.walk(output_base_dir):
    for file in files:

        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_count += 1

print(f"Total number of images in {output_base_dir}: {image_count}")

from sklearn.model_selection import train_test_split
import os
import glob


image_paths = []
labels = []

base_path = '/content/processed_gestures'

for class_name in os.listdir(base_path):
    class_folder = os.path.join(base_path, class_name)
    if os.path.isdir(class_folder):
        for img_path in glob.glob(os.path.join(class_folder, '*')):
            image_paths.append(img_path)
            labels.append(class_name)


train_paths, test_paths, train_labels, test_labels = train_test_split(
    image_paths, labels, test_size=0.2, stratify=labels, random_state=42
)

print(f"Train: {len(train_paths)} images")
print(f"Test: {len(test_paths)} images")

for i in range(1,10):
   print(train_paths[i] , train_labels[i])

import os
import shutil


output_base = '/content/split_dataset'


train_base = os.path.join(output_base, 'train')
test_base = os.path.join(output_base, 'test')
os.makedirs(train_base, exist_ok=True)
os.makedirs(test_base, exist_ok=True)

def organize_split(paths, labels, split_type):
    for path, label in zip(paths, labels):

        dest_dir = os.path.join(output_base, split_type, label)
        os.makedirs(dest_dir, exist_ok=True)


        filename = os.path.basename(path)
        dest_path = os.path.join(dest_dir, filename)
        shutil.copy2(path, dest_path)


organize_split(train_paths, train_labels, 'train')
organize_split(test_paths, test_labels, 'test')

print("Directory structure created successfully.")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = (64,64)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    shear_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/split_dataset/train',
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    '/content/split_dataset/test',
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout , BatchNormalization

model = Sequential()

model.add(Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2) ))


model.add(Conv2D(128,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(256,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10,activation='softmax'))

model.summary()

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_generator,epochs=10,validation_data=test_generator)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], color='red', label='Training Accuracy')
plt.plot(history.history['val_accuracy'],color='blue', label='Validation Accuracy')

plt.legend()
plt.show()

plt.plot(history.history['loss'], color='red', label='Training Loss')
plt.plot(history.history['val_loss'],color='blue', label='Validation Loss')

plt.legend()
plt.show()

loss, acc = model.evaluate(test_generator)
print(f"Test Accuracy: {acc:.2%}")

Result = ['A' ,'B' , 'C' ,'D' ,'E' , 'F' , 'G' , 'H' , 'I' , 'J']
paths = ['/content/split_dataset/test/01_palm/frame_00_01_0058.png' ,
         '/content/split_dataset/test/02_l/frame_00_02_0080.png',
         '/content/split_dataset/test/03_fist/frame_00_03_0034.png',
         '/content/split_dataset/test/04_fist_moved/frame_00_04_0119.png',
         '/content/split_dataset/test/05_thumb/frame_00_05_0033.png',
         '/content/split_dataset/test/06_index/frame_00_06_0035.png',
         '/content/split_dataset/test/07_ok/frame_00_07_0048.png',
         '/content/split_dataset/test/08_palm_moved/frame_00_08_0135.png',
         '/content/split_dataset/test/09_c/frame_00_09_0024.png',
         '/content/split_dataset/test/10_down/frame_00_10_0052.png']

from tensorflow.keras.preprocessing import image
import numpy as np

for i in range(0,10):

 img = image.load_img(paths[i], target_size=(64, 64))
 plt.imshow(img)
 plt.show()
 img_array = image.img_to_array(img) / 255.0
 img_array = np.expand_dims(img_array, axis=0)

 prediction = model.predict(img_array)

 predicted_class = np.argmax(prediction)
 print("Actual : " ,  Result[i])
 print("Predicted : ", Result[predicted_class])

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

img_path = '/content/TestE.jpeg'

# Load as RGB
img = image.load_img(img_path, target_size=(64, 64))  # RGB is default
plt.imshow(img)
plt.axis('off')
plt.show()

# Preprocess
img_array = image.img_to_array(img) / 255.0  # (64, 64, 3)
img_array = np.expand_dims(img_array, axis=0)  # (1, 64, 64, 3)

# Predict
prediction = model.predict(img_array)
predicted_class = np.argmax(prediction)

print("Predicted class:", Result[predicted_class])



